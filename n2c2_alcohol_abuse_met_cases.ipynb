{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koki Sasagawa\n",
    "### LHS 712 Project\n",
    "### 4/16/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from nltk.stem.lancaster import LancasterStemmer\n",
    "# from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/Users/koki/Documents/Notes/LHS_712_NLP_Health_Data/n2c2/train/'\n",
    "\n",
    "met_files = set()\n",
    "counter1 = 0\n",
    " \n",
    "for file_name in os.listdir(path_data):  # list all files in the current directory\n",
    "    tree = ET.parse(path_data + file_name)\n",
    "    if tree.find('.//ALCOHOL-ABUSE').get('met') == 'met': # retrieve tag ALCOHOL-ABUSE and get met attribute\n",
    "        counter1 += 1\n",
    "        met_files.add(file_name)\n",
    "        \n",
    "not_met_files = set()\n",
    "counter2 = 0\n",
    "\n",
    "for file_name in os.listdir(path_data):  # list all files in the current directory\n",
    "    tree = ET.parse(path_data + file_name)\n",
    "    if tree.find('.//ALCOHOL-ABUSE').get('met') == 'not met': # retrieve tag ALCOHOL-ABUSE and get met attribute\n",
    "        counter2 += 1\n",
    "        not_met_files.add(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202 total files\n",
      "7 are 'met' cases\n",
      "195 are 'not met' cases\n"
     ]
    }
   ],
   "source": [
    "print(\"%d total files\" %(counter1 + counter2))\n",
    "print(\"%d are 'met' cases\" %counter1)\n",
    "print(\"%d are 'not met' cases\" %counter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These files are:\n",
      "159.xml\n",
      "176.xml\n",
      "187.xml\n",
      "212.xml\n",
      "258.xml\n",
      "325.xml\n",
      "344.xml\n"
     ]
    }
   ],
   "source": [
    "# Name of met files\n",
    "print(\"These files are:\")\n",
    "for i in sorted(met_files):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of words related to drinking. Use as key words.\n",
    "ALCOHOL = ['drink',\n",
    "           'alcohol',\n",
    "           'etoh',\n",
    "           'ethanol']\n",
    "\n",
    "# Create list of words for defining met cases:\n",
    "# Some words retrieved from: \n",
    "# https://www.merriam-webster.com/thesaurus/alcoholism\n",
    "# https://www.projectknow.com/research/addiction-glossary-of-terms-and-phrases/\n",
    "ALCOHOL_MODIFIER = [\"abuse\",\n",
    "                    \"addiction\",\n",
    "                    \"binge\",\n",
    "                    \"concern\",\n",
    "                    \"dependence\",\n",
    "                    \"excessive\",\n",
    "                    \"heavy\"]\n",
    "\n",
    "ALCOHOL_MENTAL = [\"anxiety\",\n",
    "                  \"debauchery\",\n",
    "                  \"depression\",\n",
    "                  \"dispomania\",\n",
    "                  \"dissoluteness\",\n",
    "                  \"distraught\",\n",
    "                  \"drunkenness\",\n",
    "                  \"inebriety\",\n",
    "                  \"insobriety\",\n",
    "                  \"intemperance\",\n",
    "                  \"intoxicate\",\n",
    "                  \"bibulousness\",]\n",
    "\n",
    "NEGATION = [\"no\",\n",
    "            \"without\",\n",
    "            \"stop\",\n",
    "            \"n't\",\n",
    "            \"not\",\n",
    "            \"h/o\", \n",
    "            \"never\", \n",
    "            \"none\",  \n",
    "            \"nor\", \n",
    "            \"non\",\n",
    "            \"rare\",\n",
    "            \"previous\",\n",
    "            \"prior\",\n",
    "            \"history\",\n",
    "            \"denies\",\n",
    "            \"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drink', 'alcohol', 'etoh', 'ethanol']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_alcohol = [snowball_stemmer.stem(word) for word in ALCOHOL]\n",
    "stemmed_alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abus', 'addict', 'bing', 'concern', 'depend', 'excess', 'heavi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_alcohol_modifer = [snowball_stemmer.stem(word) for word in ALCOHOL_MODIFIER]\n",
    "stemmed_alcohol_modifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anxieti',\n",
       " 'debaucheri',\n",
       " 'depress',\n",
       " 'dispomania',\n",
       " 'dissolut',\n",
       " 'distraught',\n",
       " 'drunken',\n",
       " 'inebrieti',\n",
       " 'insobrieti',\n",
       " 'intemper',\n",
       " 'intox',\n",
       " 'bibul']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_alcohol_mental = [snowball_stemmer.stem(word) for word in ALCOHOL_MENTAL]\n",
    "stemmed_alcohol_mental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no',\n",
       " 'without',\n",
       " 'stop',\n",
       " \"n't\",\n",
       " 'not',\n",
       " 'h/o',\n",
       " 'never',\n",
       " 'none',\n",
       " 'nor',\n",
       " 'non',\n",
       " 'rare',\n",
       " 'previous',\n",
       " 'prior',\n",
       " 'histori',\n",
       " 'deni',\n",
       " 'negat']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_negation = [snowball_stemmer.stem(word) for word in NEGATION]\n",
    "stemmed_negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN SCRIPT\n",
    "met_predictions = set()\n",
    "not_met_predictions = set()\n",
    "\n",
    "for file_name in os.listdir(path_data):\n",
    "    tree=ET.parse(path_data + file_name)\n",
    "    raw_text = tree.find('.//TEXT').text\n",
    "\n",
    "    clean_text = re.sub('\\\\n', ' ', raw_text)\n",
    "    clean_text = re.sub('\\\\t','', clean_text)\n",
    "    clean_text = re.sub('[\\s]{2,}', ' ', clean_text)\n",
    "\n",
    "    sentences = nltk.sent_tokenize(clean_text)\n",
    "    # sentences = nltk.sent_tokenize(raw_text)\n",
    "    \n",
    "    hotspot_lines = set()\n",
    "\n",
    "    for i in sentences:\n",
    "        # filter out anything non-alphabetical characters and a few special characters\n",
    "        tokenizer = RegexpTokenizer(r'[a-zA-Z\\/\\']+')\n",
    "        token = tokenizer.tokenize(i)\n",
    "\n",
    "        # Different Stemmers\n",
    "\n",
    "        # wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        # lemmatized_tokens = [wordnet_lemmatizer.lemmatize(word) for word in tagged_token]\n",
    "\n",
    "        # lancaster_stemmer = LancasterStemmer()\n",
    "        # stemmed_tokens = [lancaster_stemmer.stem(word) for word in token]\n",
    "\n",
    "        # porter_stemmer = PorterStemmer()\n",
    "        # stemmed_tokens = [porter_stemmer.stem(word) for word in token]\n",
    "\n",
    "        snowball_stemmer = SnowballStemmer(\"english\")\n",
    "        stemmed_tokens = [snowball_stemmer.stem(word.lower()) for word in token]\n",
    "\n",
    "        drink_score = 0\n",
    "        abuse_score = 0\n",
    "\n",
    "        for j in range(len(stemmed_tokens)):\n",
    "            if stemmed_tokens[j] in stemmed_alcohol:\n",
    "                drink_score += 1\n",
    "                # Negation Detection in negative direction\n",
    "                if (j > 0) and (stemmed_tokens[j - 1] in stemmed_negation):\n",
    "                    drink_score = 0\n",
    "                elif (j > 1) and (stemmed_tokens[j - 2] in stemmed_negation):\n",
    "                    drink_score = 0\n",
    "                elif (j > 2) and (stemmed_tokens[j - 3] in stemmed_negation):\n",
    "                    drink_score = 0\n",
    "                elif (j > 3) and (stemmed_tokens[j - 4] in stemmed_negation):\n",
    "                    drink_score = 0\n",
    "                elif (j > 4) and (stemmed_tokens[j - 5] in stemmed_negation):\n",
    "                    drink_score = 0\n",
    "                # Negation Detection in positive direction\n",
    "                elif (j < len(stemmed_tokens) - 1) and (stemmed_tokens[j + 1] in stemmed_negation):\n",
    "                    drink_score = 0\n",
    "                elif (j < len(stemmed_tokens) - 2) and (stemmed_tokens[j + 2] in stemmed_negation):\n",
    "                    drink_score = 0\n",
    "                elif (j < len(stemmed_tokens) - 3) and (stemmed_tokens[j + 3] in stemmed_negation):\n",
    "                    drink_score = 0\n",
    "                # Positive Modifer Detection\n",
    "                elif (j > 0) and (stemmed_tokens[j - 1] in stemmed_alcohol_modifer):\n",
    "                    abuse_score += 1\n",
    "                elif (j > 1) and (stemmed_tokens[j - 2] in stemmed_alcohol_modifer):\n",
    "                    abuse_score += 1\n",
    "                elif (j < len(stemmed_tokens) - 1) and (stemmed_tokens[j + 1] in stemmed_alcohol_modifer):\n",
    "                    abuse_score += 1\n",
    "                elif (j < len(stemmed_tokens) - 2) and (stemmed_tokens[j + 2] in stemmed_alcohol_modifer):\n",
    "                    abuse_score += 1\n",
    "            # Mental Health Detection    \n",
    "            elif stemmed_tokens[j] in stemmed_alcohol_mental:\n",
    "                abuse_score += 1\n",
    "        if drink_score >= 1 and abuse_score >= 1:\n",
    "            hotspot_lines.add(i)\n",
    "\n",
    "    if hotspot_lines:\n",
    "        met_predictions.add(file_name)\n",
    "    else:\n",
    "        not_met_predictions.add(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'110.xml',\n",
       " '159.xml',\n",
       " '176.xml',\n",
       " '187.xml',\n",
       " '188.xml',\n",
       " '210.xml',\n",
       " '212.xml',\n",
       " '319.xml',\n",
       " '325.xml',\n",
       " '344.xml',\n",
       " '356.xml'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 6\n",
      "False positives: 5\n",
      "True negatives: 190\n",
      "False negatives: 1\n",
      "Sensitivity (True Positive Rate): 0.86\n",
      "Specificity (True Negative Rate): 0.97\n",
      "Precision: 0.55\n",
      "Accuracy: 0.97\n",
      "F1 score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Performance Results\n",
    "\n",
    "P = counter1\n",
    "N = counter2 \n",
    "\n",
    "# True positive is the event that test makes a positive prediction and the\n",
    "# subject has a positive result under the gold standard\n",
    "TP = 0\n",
    "for file in met_files:\n",
    "    if file in met_predictions:\n",
    "        TP += 1\n",
    "        \n",
    "# True negative is the event that the test makes a negative prediction and \n",
    "#  the subject has a negative result under the gold standard\n",
    "TN = 0\n",
    "for file in not_met_files:\n",
    "    if file in not_met_predictions:\n",
    "        TN += 1 \n",
    "        \n",
    "# False positive is the event that the test makes a positive prediction and \n",
    "# the subject has a negative result under the gold standard. \n",
    "FP = N - TN\n",
    "\n",
    "# False negative is the event that the test makes a negative prediction and\n",
    "# the subject has a positive result under the gold standard\n",
    "FN = P - TP\n",
    "\n",
    "# The fraction of relevant positive instances among retrieved positive instances\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "# Closeness of a measured value to standard\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "f1_score = (2 * TP) / ((2 * TP) + FP + FN)\n",
    "\n",
    "# Print Results \n",
    "print(\"True positives: %d\" %TP)\n",
    "print(\"False positives: %d\" %(FP))\n",
    "print(\"True negatives: %d\" %TN)\n",
    "print(\"False negatives: %d\" %(FN))\n",
    "print(\"Sensitivity (True Positive Rate): %0.2f\" %(TP / P))\n",
    "print(\"Specificity (True Negative Rate): %0.2f\" %(TN / N))\n",
    "print(\"Precision: %0.2f\" %precision)\n",
    "print(\"Accuracy: %0.2f\" %accuracy)\n",
    "print(\"F1 score: %0.2f\" %f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine(i):\n",
    "#     \"\"\" This recursive functinon will add consecutively occuring lines together \"\"\"\n",
    "#     if i < N and trimmed_lines[i]:\n",
    "#         line = trimmed_lines[i]\n",
    "#         trimmed_lines[i] = ''\n",
    "#         return line + ' ' + combine(i+1)\n",
    "#     return ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
